Things to do:

* Additional dfxml stuff
 - see ttd.dfxml.1

* fiwalk doesn't generate a hash on this one, and it should:
    <fileobject>
      <filename>Program Files/Java/jre6/bin/client/classes.jsa</filename>
      <partition>1</partition>
      <id>2798</id>
      <name_type>r</name_type>
      <filesize>13172736</filesize>
      <alloc>1</alloc>
      <used>1</used>
      <inode>52492</inode>
      <meta_type>1</meta_type>
      <mode>219</mode>
      <nlink>1</nlink>
      <uid>0</uid>
      <gid>0</gid>
      <mtime>1259101479</mtime>
      <ctime>1259101482</ctime>
      <atime>1259101479</atime>
      <crtime>1259101479</crtime>
      <seq>4</seq>
<!-- NTFS and attr=0x100534160 -->
      <byte_runs>
       <run file_offset='0' fs_offset='1754738688' img_offset='1755787264' len='13144064'/>
       <run file_offset='13144064' fill='0' len='28672'/>
      </byte_runs>
    </fileobject>

* Needs much better handling of NTFS compressed files - each byte run is coming up separately.

* Properly handle byte_runs for compressed files.

* Make this program multi-threaded so that the analysis happens in
  another thread (one thread for every file?)

* have every attribute get generated for every record/instance, and in
the same order, all the time. not having this makes batch processing
somewhat of a nightmare. optionally, ask the user to specify not just
which plugins they want, but which attributes they want to gather and
in what order.

* get fiwalk to spit out the UID of the file owner from inode
  information on disk.

* get fiwalk to spit out the file permissions (in a common format)
  from the inode information on disk (note: windows representation of
  permissions is complex, so this could be finicky)

* check why we arent getting more embedded date/time stamps from the
  extended fiwalk plugins. are the timestamps really not there? or is
  something wrong? (note: .ppt embedded metadata extraction seems to be
  working well). 

* WPD embedded metadata support?

* better escaping of special characters in filenames (maybe just
always quote filenames by default, even if there's no spaces?) (maybe just always quote every non-numeric attribute?)

* combine the runs on compressed byteruns, for restore point (see domexusers)

Upgrade to cycle through all attributes. See http://www.sleuthkit.org/sleuthkit/docs/api-docs/fspage.html


    /* print a * if it is deleted */
    if (fs_file->name->flags & TSK_FS_NAME_FLAG_UNALLOC)
        tsk_fprintf(hFile, "* ");

    tsk_fprintf(hFile, "%" PRIuINUM "", fs_file->name->meta_addr);

    /* print the id and type if we have fs_attr (NTFS) */
    if (fs_attr)
        tsk_fprintf(hFile, "-%" PRIu32 "-%" PRIu16 "", fs_attr->type,
            fs_attr->id);

    tsk_fprintf(hFile, "%s:\t",
        ((fs_file->meta) && (fs_file->meta->flags & TSK_FS_META_FLAG_ALLOC)
            && (fs_file->name->
                flags & TSK_FS_NAME_FLAG_UNALLOC)) ? "(realloc)" : "");

    if ((print_path) && (a_path != NULL))
        tsk_fprintf(hFile, "%s", a_path);

    tsk_fprintf(hFile, "%s", fs_file->name->name);


I think that might be a good idea, or at least have a command line
option to enable it.
Some Linux rootkits did:

# cp /bin/sh /tmp/bd
# chmod +s /tmp/bd

...or just:

# chmod +s /bin/sh


================================================================
Hey Simson,


On Jul 17, 2011, at 9:22 PM, Simson Garfinkel wrote:

I'm having a problem with the file_acct callback function called from tsk_fs_file_walk when processing compressed files. That is, when the flag TSK_FS_BLOCK_FLAG_COMP is set.

An existing problem that I've previously noted is that the callback provides the location on the disk of the compressed data, but TSK doesn't provide an exposed function which allows me to provide the on-disk data and decompress it.

The internal function is ntfs_uncompress_compunit() in tsk3/fs/ntfs.c.  It currently has a static scope in the file, but I could change that. Can you look at that method to see if it is what you are looking for?

For blocks that are not compressed, I know that it can be extended if the image offset plus the length of the previous block is equal to the image offset of the following block. But I don't see any obvious way to do that with compressed files. 

The problem that I am having now has to do with the coalescing of compressed blocks. To which, the callback is called for each 512-byte block in the file. How can I tell if it is safe to combine two blocks into a single run that is decompressed as a whole?


Here is how it currently works:
* NTFS breaks the original data up into compression units (I think 16 clusters is the default).  It tries to compress them and if it compresses to less than 15 clusters, it stores those clusters compressed. Let's say that it compresses to 10 clusters.  The NTFS attribute is saved as having 10 clusters with compressed data and then 6 sparse clusters (which don't point to a specific cluster address). 
* The file_walk callback will get called 16 times for this unit.  Each time it will return a chunk equal to the block size. The first 10 times the callback will get a cluster address that stored file content. The last 6 times it will continue to get uncompressed file content, but it will have an address of 0.  If you are seeing behavior different from this, let me know.

So, your previous approach of saving the previous cluster address and making sure that it increments by 1 each time should still work. You'll just need to handle the extra 0s in there.   You can also manually parse teh TSK_FS_ATTR structures if you want. Those are stored as run lists, so it will give you the extent information.

brian


